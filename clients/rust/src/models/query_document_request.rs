/*
 * Studio - AI Empower Labs
 *
 * # Studio API Documentation  ## Introduction Welcome to Studio by AI Empower Labs API documentation! We are thrilled to offer developers around the world access to our cutting-edge artificial intelligence technology and semantic search. Our API is designed to empower your applications with state-of-the-art AI capabilities, including but not limited to natural language processing, audio transcription, embedding, and predictive analytics.  Our mission is to make AI technology accessible and easy to integrate, enabling you to enhance your applications, improve user experiences, and innovate in your field. Whether you're building complex systems, developing mobile apps, or creating web services, our API provides you with the tools you need to incorporate AI functionalities seamlessly.  Support and Feedback We are committed to providing exceptional support to our developer community. If you have any questions, encounter any issues, or have feedback on how we can improve our API, please don't hesitate to contact our support team @ support@AIEmpowerLabs.com.  Terms of Use Please review our terms of use and privacy policy before integrating our API into your application. By using our API, you agree to comply with these terms.
 *
 * The version of the OpenAPI document: v1
 * Contact: support@aiempowerlabs.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct QueryDocumentRequest {
    /// Semantic query to find matching documents
    #[serde(rename = "query", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub query: Option<Option<String>>,
    /// Optional index to specify which index to search in. Defaults to 'default'
    #[serde(rename = "index", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub index: Option<Option<String>>,
    /// Optional filtering of document id(s) and/or tags
    #[serde(rename = "filter", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub filter: Option<Option<Vec<models::DocumentFilters>>>,
    /// Optional search mode defining the context or process used in the query. Supported values are 'hybrid', 'semantic'
    #[serde(rename = "searchMode", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub search_mode: Option<Option<SearchMode>>,
    /// Specifies the language of the content.
    #[serde(rename = "language", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub language: Option<Option<String>>,
    /// Indicates whether language detection is enabled.
    #[serde(rename = "languageDetection", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub language_detection: Option<Option<bool>>,
    /// Minimum score for full-text search.
    #[serde(rename = "ftsMinScore", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub fts_min_score: Option<Option<f32>>,
    /// Weight for full-text search.
    #[serde(rename = "ftsWeight", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub fts_weight: Option<Option<f32>>,
    /// Minimum relevance score for semantic search.
    #[serde(rename = "semanticMinRelevance", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub semantic_min_relevance: Option<Option<f64>>,
    /// Weight applied for semantic search.
    #[serde(rename = "semanticWeight", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub semantic_weight: Option<Option<f32>>,
    /// Smoothing factor (k) used in calculations.
    #[serde(rename = "smoothingFactorK", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub smoothing_factor_k: Option<Option<f32>>,
    /// Optional filter to specify minimum relevance. Typically values between 0 and 1
    #[serde(rename = "minRelevance", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub min_relevance: Option<Option<f64>>,
    /// Optional filter for specifying maximum number of entries to return. Defaults to 3
    #[serde(rename = "limit", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub limit: Option<Option<i32>>,
    /// Embedding model to use in query
    #[serde(rename = "embeddingModel", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub embedding_model: Option<Option<String>>,
    #[serde(rename = "args", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub args: Option<Option<std::collections::HashMap<String, serde_json::Value>>>,
}

impl QueryDocumentRequest {
    pub fn new() -> QueryDocumentRequest {
        QueryDocumentRequest {
            query: None,
            index: None,
            filter: None,
            search_mode: None,
            language: None,
            language_detection: None,
            fts_min_score: None,
            fts_weight: None,
            semantic_min_relevance: None,
            semantic_weight: None,
            smoothing_factor_k: None,
            min_relevance: None,
            limit: None,
            embedding_model: None,
            args: None,
        }
    }
}
/// Optional search mode defining the context or process used in the query. Supported values are 'hybrid', 'semantic'
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum SearchMode {
    #[serde(rename = "hybrid")]
    Hybrid,
    #[serde(rename = "semantic")]
    Semantic,
}

impl Default for SearchMode {
    fn default() -> SearchMode {
        Self::Hybrid
    }
}

