/*
 * Studio - AI Empower Labs
 *
 * # Studio API Documentation  ## Introduction Welcome to Studio by AI Empower Labs API documentation! We are thrilled to offer developers around the world access to our cutting-edge artificial intelligence technology and semantic search. Our API is designed to empower your applications with state-of-the-art AI capabilities, including but not limited to natural language processing, audio transcription, embedding, and predictive analytics.  Our mission is to make AI technology accessible and easy to integrate, enabling you to enhance your applications, improve user experiences, and innovate in your field. Whether you're building complex systems, developing mobile apps, or creating web services, our API provides you with the tools you need to incorporate AI functionalities seamlessly.  Support and Feedback We are committed to providing exceptional support to our developer community. If you have any questions, encounter any issues, or have feedback on how we can improve our API, please don't hesitate to contact our support team @ support@AIEmpowerLabs.com.  Terms of Use Please review our terms of use and privacy policy before integrating our API into your application. By using our API, you agree to comply with these terms.
 *
 * The version of the OpenAPI document: v1
 * Contact: support@aiempowerlabs.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct IngestTextDocumentRequest {
    /// Id that uniquely identifies content. Previously ingested documents with the same id will be overwritten
    #[serde(rename = "documentId")]
    pub document_id: String,
    /// Optional value to specify with index the document should be ingested. Defaults to 'default'
    #[serde(rename = "index", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub index: Option<Option<String>>,
    /// Optionally add tags to ingestion
    #[serde(rename = "tags", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub tags: Option<Option<std::collections::HashMap<String, Vec<String>>>>,
    /// Text to ingest
    #[serde(rename = "text")]
    pub text: String,
    /// Optional value to specify ingestion pipeline steps. Defaults to server configured defaults.
    #[serde(rename = "pipeline", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub pipeline: Option<Option<Vec<String>>>,
    /// Url to use for webhook callback when operation finishes or fails.
    #[serde(rename = "webHookUrl", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub web_hook_url: Option<Option<String>>,
    /// Embedding model to use in ingestion. Optional. Default to configured default.
    #[serde(rename = "embeddingModel", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub embedding_model: Option<Option<String>>,
    #[serde(rename = "args", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub args: Option<Option<std::collections::HashMap<String, serde_json::Value>>>,
}

impl IngestTextDocumentRequest {
    pub fn new(document_id: String, text: String) -> IngestTextDocumentRequest {
        IngestTextDocumentRequest {
            document_id,
            index: None,
            tags: None,
            text,
            pipeline: None,
            web_hook_url: None,
            embedding_model: None,
            args: None,
        }
    }
}

