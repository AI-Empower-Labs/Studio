/*
 * Studio - AI Empower Labs
 *
 * # Studio API Documentation  ## Introduction Welcome to Studio by AI Empower Labs API documentation! We are thrilled to offer developers around the world access to our cutting-edge artificial intelligence technology and semantic search. Our API is designed to empower your applications with state-of-the-art AI capabilities, including but not limited to natural language processing, audio transcription, embedding, and predictive analytics.  Our mission is to make AI technology accessible and easy to integrate, enabling you to enhance your applications, improve user experiences, and innovate in your field. Whether you're building complex systems, developing mobile apps, or creating web services, our API provides you with the tools you need to incorporate AI functionalities seamlessly.  Support and Feedback We are committed to providing exceptional support to our developer community. If you have any questions, encounter any issues, or have feedback on how we can improve our API, please don't hesitate to contact our support team @ support@AIEmpowerLabs.com.  Terms of Use Please review our terms of use and privacy policy before integrating our API into your application. By using our API, you agree to comply with these terms.
 *
 * The version of the OpenAPI document: v1
 * Contact: support@aiempowerlabs.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct SemanticSearchQueryResultsClusteringRequest {
    /// The number of clusters to be used in k-means clustering.
    #[serde(rename = "clusterCount", skip_serializing_if = "Option::is_none")]
    pub cluster_count: Option<i32>,
    /// The Maximum Degrees Of Parallelism
    #[serde(rename = "maxDegreeOfParallelism", skip_serializing_if = "Option::is_none")]
    pub max_degree_of_parallelism: Option<i32>,
    /// The maximum number of tokens to be used in the KMeans clustering algorithm.
    #[serde(rename = "maxTokens", skip_serializing_if = "Option::is_none")]
    pub max_tokens: Option<i32>,
    /// Optional index to specify which index to search in. Defaults to 'default'.
    #[serde(rename = "index", skip_serializing_if = "Option::is_none")]
    pub index: Option<String>,
    /// The minimum relevance value used for querying the search result audit.
    #[serde(rename = "minRelevance", skip_serializing_if = "Option::is_none")]
    pub min_relevance: Option<f64>,
    /// The maximum relevance value to be used in the search query.
    #[serde(rename = "maxRelevance", skip_serializing_if = "Option::is_none")]
    pub max_relevance: Option<f64>,
    /// Specifies the name of the LLM (Language Model) to be used in the KMeans clustering algorithm.
    #[serde(rename = "llmModel", skip_serializing_if = "Option::is_none")]
    pub llm_model: Option<String>,
    /// The name of the embedding model used for clustering.
    #[serde(rename = "embeddingModel", skip_serializing_if = "Option::is_none")]
    pub embedding_model: Option<String>,
}

impl SemanticSearchQueryResultsClusteringRequest {
    pub fn new() -> SemanticSearchQueryResultsClusteringRequest {
        SemanticSearchQueryResultsClusteringRequest {
            cluster_count: None,
            max_degree_of_parallelism: None,
            max_tokens: None,
            index: None,
            min_relevance: None,
            max_relevance: None,
            llm_model: None,
            embedding_model: None,
        }
    }
}

