/**
 *
 * Please note:
 * This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * Do not edit this file manually.
 *
 */

@file:Suppress(
    "ArrayInDataClass",
    "EnumEntryName",
    "RemoveRedundantQualifierName",
    "UnusedImport"
)

package org.openapitools.client.apis

import java.io.IOException
import okhttp3.Call
import okhttp3.HttpUrl

import org.openapitools.client.models.HttpValidationProblemDetails
import org.openapitools.client.models.ProblemDetails
import org.openapitools.client.models.TranscriptionAudioUploadResult

import com.squareup.moshi.Json

import org.openapitools.client.infrastructure.ApiClient
import org.openapitools.client.infrastructure.ApiResponse
import org.openapitools.client.infrastructure.ClientException
import org.openapitools.client.infrastructure.ClientError
import org.openapitools.client.infrastructure.ServerException
import org.openapitools.client.infrastructure.ServerError
import org.openapitools.client.infrastructure.MultiValueMap
import org.openapitools.client.infrastructure.PartConfig
import org.openapitools.client.infrastructure.RequestConfig
import org.openapitools.client.infrastructure.RequestMethod
import org.openapitools.client.infrastructure.ResponseType
import org.openapitools.client.infrastructure.Success
import org.openapitools.client.infrastructure.toMultiValue

class TranscriptionApi(basePath: kotlin.String = defaultBasePath, client: Call.Factory = ApiClient.defaultClient) : ApiClient(basePath, client) {
    companion object {
        @JvmStatic
        val defaultBasePath: String by lazy {
            System.getProperties().getProperty(ApiClient.baseUrlKey, "https://studio.aiempowerlabs.com")
        }
    }

    /**
     * enum for parameter model
     */
     enum class ModelTranscriptionAsynchronous(val value: kotlin.String) {
         @Json(name = "tiny") tiny("tiny"),
         @Json(name = "tiny.en") tinyPeriodEn("tiny.en"),
         @Json(name = "base") base("base"),
         @Json(name = "base.en") basePeriodEn("base.en"),
         @Json(name = "small") small("small"),
         @Json(name = "small.en") smallPeriodEn("small.en"),
         @Json(name = "medium") medium("medium"),
         @Json(name = "medium.en") mediumPeriodEn("medium.en"),
         @Json(name = "large_v1") large_v1("large_v1"),
         @Json(name = "large_v2") large_v2("large_v2"),
         @Json(name = "large_v3") large_v3("large_v3");

        /**
         * Override [toString()] to avoid using the enum variable name as the value, and instead use
         * the actual value defined in the API spec file.
         *
         * This solves a problem when the variable name and its value are different, and ensures that
         * the client sends the correct enum values to the server always.
         */
        override fun toString(): kotlin.String = "$value"
     }

    /**
     * Upload audio file for asynchronous transcription
     * This service is designed to convert spoken words from audio or video files into written text, utilizing sophisticated speech recognition algorithms for accurate transcription. It offers a range of features that cater to various needs and use cases, making it particularly valuable for journalists, researchers, podcasters, and professionals dealing with meetings, interviews, lectures, or presentations.  ### Key features and capabilities include:  * Support for Various File Formats: Accepts a wide range of audio and video file formats, ensuring flexibility in file uploads. * Advanced Processing Steps: Incorporates noise reduction, speaker diarization, and speech-to-text conversion for clear and differentiated transcriptions. * Asynchronous Background Processing: Allows for non-blocking, efficient handling of transcription tasks, suitable for large files or batches of files. * Webhook Callback URL: Offers real-time updates on the transcription process via a provided webhook, enabling immediate reaction to task completion or failure. * /api/transcribe GET Endpoint: Provides an alternative for users to manually check the status of their transcription requests, allowing flexibility in monitoring. * Automatic Text Translation Feature: An optional service that translates the transcribed text into a specified target language, enhancing the utility for multi-lingual contexts. * Multi-File and Multi-Channel Support: Supports concurrent file uploads and accurate transcription of multi-channel recordings, ideal for complex audio environments. * The transcription output is meticulously formatted to clearly distinguish between channels and speakers, including timestamps and labels for easy navigation and reference. This structured approach ensures that even in challenging audio environments with multiple speakers or channels, the transcription service can provide clear, accurate, and useful text representations of the spoken content.  This service integrates into applications via API calls, offering developers a powerful tool to enhance their applications with audio-to-text conversion capabilities. The inclusion of features like language detection, support for multiple languages, and customization options for specific vocabulary or industry terms further extends its applicability across various domains and industries.
     * @param files The file object to ingest.
     * @param model Model to use for transcription (Optional, default &#x3D; Base) (optional)
     * @param language The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.  (optional) (optional)
     * @param prompt An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should match the audio language.  (optional) (optional)
     * @param temperature The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.  (optional, default to 0M) (optional, default to 0.0)
     * @param webHookUrl Url to call when transcription has completed or failed. (optional) (optional)
     * @param translateTo The language to translate transcription into. Supplying the language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.  (optional) (optional)
     * @param splitOnWord Split into word segments. (optional, default is false) (optional, default to false)
     * @param languageDetection Enable transcription language detection (Optional. default is false) (optional, default to false)
     * @param enableNoiseReduction Enable noise reduction from audio stream before transcription (Optional. default is false) (optional, default to false)
     * @return TranscriptionAudioUploadResult
     * @throws IllegalStateException If the request is not correctly configured
     * @throws IOException Rethrows the OkHttp execute method exception
     * @throws UnsupportedOperationException If the API returns an informational or redirection response
     * @throws ClientException If the API returns a client error response
     * @throws ServerException If the API returns a server error response
     */
    @Suppress("UNCHECKED_CAST")
    @Throws(IllegalStateException::class, IOException::class, UnsupportedOperationException::class, ClientException::class, ServerException::class)
    fun transcriptionAsynchronous(files: kotlin.collections.List<java.io.File>, model: ModelTranscriptionAsynchronous? = null, language: kotlin.String? = null, prompt: kotlin.String? = null, temperature: kotlin.Double? = 0.0, webHookUrl: java.net.URI? = null, translateTo: kotlin.String? = null, splitOnWord: kotlin.Boolean? = false, languageDetection: kotlin.Boolean? = false, enableNoiseReduction: kotlin.Boolean? = false) : TranscriptionAudioUploadResult {
        val localVarResponse = transcriptionAsynchronousWithHttpInfo(files = files, model = model, language = language, prompt = prompt, temperature = temperature, webHookUrl = webHookUrl, translateTo = translateTo, splitOnWord = splitOnWord, languageDetection = languageDetection, enableNoiseReduction = enableNoiseReduction)

        return when (localVarResponse.responseType) {
            ResponseType.Success -> (localVarResponse as Success<*>).data as TranscriptionAudioUploadResult
            ResponseType.Informational -> throw UnsupportedOperationException("Client does not support Informational responses.")
            ResponseType.Redirection -> throw UnsupportedOperationException("Client does not support Redirection responses.")
            ResponseType.ClientError -> {
                val localVarError = localVarResponse as ClientError<*>
                throw ClientException("Client error : ${localVarError.statusCode} ${localVarError.message.orEmpty()}", localVarError.statusCode, localVarResponse)
            }
            ResponseType.ServerError -> {
                val localVarError = localVarResponse as ServerError<*>
                throw ServerException("Server error : ${localVarError.statusCode} ${localVarError.message.orEmpty()} ${localVarError.body}", localVarError.statusCode, localVarResponse)
            }
        }
    }

    /**
     * Upload audio file for asynchronous transcription
     * This service is designed to convert spoken words from audio or video files into written text, utilizing sophisticated speech recognition algorithms for accurate transcription. It offers a range of features that cater to various needs and use cases, making it particularly valuable for journalists, researchers, podcasters, and professionals dealing with meetings, interviews, lectures, or presentations.  ### Key features and capabilities include:  * Support for Various File Formats: Accepts a wide range of audio and video file formats, ensuring flexibility in file uploads. * Advanced Processing Steps: Incorporates noise reduction, speaker diarization, and speech-to-text conversion for clear and differentiated transcriptions. * Asynchronous Background Processing: Allows for non-blocking, efficient handling of transcription tasks, suitable for large files or batches of files. * Webhook Callback URL: Offers real-time updates on the transcription process via a provided webhook, enabling immediate reaction to task completion or failure. * /api/transcribe GET Endpoint: Provides an alternative for users to manually check the status of their transcription requests, allowing flexibility in monitoring. * Automatic Text Translation Feature: An optional service that translates the transcribed text into a specified target language, enhancing the utility for multi-lingual contexts. * Multi-File and Multi-Channel Support: Supports concurrent file uploads and accurate transcription of multi-channel recordings, ideal for complex audio environments. * The transcription output is meticulously formatted to clearly distinguish between channels and speakers, including timestamps and labels for easy navigation and reference. This structured approach ensures that even in challenging audio environments with multiple speakers or channels, the transcription service can provide clear, accurate, and useful text representations of the spoken content.  This service integrates into applications via API calls, offering developers a powerful tool to enhance their applications with audio-to-text conversion capabilities. The inclusion of features like language detection, support for multiple languages, and customization options for specific vocabulary or industry terms further extends its applicability across various domains and industries.
     * @param files The file object to ingest.
     * @param model Model to use for transcription (Optional, default &#x3D; Base) (optional)
     * @param language The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.  (optional) (optional)
     * @param prompt An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should match the audio language.  (optional) (optional)
     * @param temperature The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.  (optional, default to 0M) (optional, default to 0.0)
     * @param webHookUrl Url to call when transcription has completed or failed. (optional) (optional)
     * @param translateTo The language to translate transcription into. Supplying the language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.  (optional) (optional)
     * @param splitOnWord Split into word segments. (optional, default is false) (optional, default to false)
     * @param languageDetection Enable transcription language detection (Optional. default is false) (optional, default to false)
     * @param enableNoiseReduction Enable noise reduction from audio stream before transcription (Optional. default is false) (optional, default to false)
     * @return ApiResponse<TranscriptionAudioUploadResult?>
     * @throws IllegalStateException If the request is not correctly configured
     * @throws IOException Rethrows the OkHttp execute method exception
     */
    @Suppress("UNCHECKED_CAST")
    @Throws(IllegalStateException::class, IOException::class)
    fun transcriptionAsynchronousWithHttpInfo(files: kotlin.collections.List<java.io.File>, model: ModelTranscriptionAsynchronous?, language: kotlin.String?, prompt: kotlin.String?, temperature: kotlin.Double?, webHookUrl: java.net.URI?, translateTo: kotlin.String?, splitOnWord: kotlin.Boolean?, languageDetection: kotlin.Boolean?, enableNoiseReduction: kotlin.Boolean?) : ApiResponse<TranscriptionAudioUploadResult?> {
        val localVariableConfig = transcriptionAsynchronousRequestConfig(files = files, model = model, language = language, prompt = prompt, temperature = temperature, webHookUrl = webHookUrl, translateTo = translateTo, splitOnWord = splitOnWord, languageDetection = languageDetection, enableNoiseReduction = enableNoiseReduction)

        return request<Map<String, PartConfig<*>>, TranscriptionAudioUploadResult>(
            localVariableConfig
        )
    }

    /**
     * To obtain the request config of the operation transcriptionAsynchronous
     *
     * @param files The file object to ingest.
     * @param model Model to use for transcription (Optional, default &#x3D; Base) (optional)
     * @param language The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.  (optional) (optional)
     * @param prompt An optional text to guide the model&#39;s style or continue a previous audio segment. The prompt should match the audio language.  (optional) (optional)
     * @param temperature The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.  (optional, default to 0M) (optional, default to 0.0)
     * @param webHookUrl Url to call when transcription has completed or failed. (optional) (optional)
     * @param translateTo The language to translate transcription into. Supplying the language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.  (optional) (optional)
     * @param splitOnWord Split into word segments. (optional, default is false) (optional, default to false)
     * @param languageDetection Enable transcription language detection (Optional. default is false) (optional, default to false)
     * @param enableNoiseReduction Enable noise reduction from audio stream before transcription (Optional. default is false) (optional, default to false)
     * @return RequestConfig
     */
    fun transcriptionAsynchronousRequestConfig(files: kotlin.collections.List<java.io.File>, model: ModelTranscriptionAsynchronous?, language: kotlin.String?, prompt: kotlin.String?, temperature: kotlin.Double?, webHookUrl: java.net.URI?, translateTo: kotlin.String?, splitOnWord: kotlin.Boolean?, languageDetection: kotlin.Boolean?, enableNoiseReduction: kotlin.Boolean?) : RequestConfig<Map<String, PartConfig<*>>> {
        val localVariableBody = mapOf(
            "files" to PartConfig(body = files, headers = mutableMapOf()),)
        val localVariableQuery: MultiValueMap = mutableMapOf<kotlin.String, kotlin.collections.List<kotlin.String>>()
            .apply {
                if (model != null) {
                    put("model", listOf(model.value))
                }
                if (language != null) {
                    put("language", listOf(language.toString()))
                }
                if (prompt != null) {
                    put("prompt", listOf(prompt.toString()))
                }
                if (temperature != null) {
                    put("temperature", listOf(temperature.toString()))
                }
                if (webHookUrl != null) {
                    put("webHookUrl", listOf(webHookUrl.toString()))
                }
                if (translateTo != null) {
                    put("translateTo", listOf(translateTo.toString()))
                }
                if (splitOnWord != null) {
                    put("splitOnWord", listOf(splitOnWord.toString()))
                }
                if (languageDetection != null) {
                    put("languageDetection", listOf(languageDetection.toString()))
                }
                if (enableNoiseReduction != null) {
                    put("enableNoiseReduction", listOf(enableNoiseReduction.toString()))
                }
            }
        val localVariableHeaders: MutableMap<String, String> = mutableMapOf("Content-Type" to "multipart/form-data")
        localVariableHeaders["Accept"] = "application/json, application/problem+json"

        return RequestConfig(
            method = RequestMethod.POST,
            path = "/api/transcribe/upload",
            query = localVariableQuery,
            headers = localVariableHeaders,
            requiresAuthentication = false,
            body = localVariableBody
        )
    }

    /**
     * Get transcription status and data
     * The /api/transcribe GET endpoint is a crucial component of the audio transcription service, designed to offer users a way to check the status of their transcription requests. This endpoint caters to the needs of users who prefer polling to monitor their requests over relying on webhook callbacks for real-time updates. Here&#39;s a detailed description of its functionality and how it integrates within the service:  ### Purpose and Functionality The primary purpose of the /api/transcribe GET endpoint is to provide users with the ability to manually inquire about the current status of their audio or video file transcription tasks. This endpoint supports a polling mechanism, where users can send a GET request at their convenience to receive the latest update on their transcription process.  ### How It Works Request: To utilize this endpoint, users initiate a GET request, including a unique identifier for the transcription task as a parameter. This identifier is provided by the service when the transcription request is first submitted. Response: In response to the GET request, the endpoint returns data about the transcription task&#39;s status. The response indicate that the transcription is still processing, has been completed, or has failed.  ### Response Details The response from the /api/transcribe GET endpoint includes several pieces of information that are crucial for users to understand the status and outcome of their transcription requests:  Status: Indicates the current state of the transcription task (e.g., Queued, Completed, Failed). Completion Details: If the transcription is completed, the response include details the resulting transcript.  ### Use Cases This endpoint is particularly useful for scenarios where users need or prefer to periodically check the status of their requests rather than implement real-time update mechanisms via webhooks. It provides flexibility in handling transcription tasks, allowing users to:  ### Advantages The /api/transcribe GET endpoint offers several advantages, including simplicity in implementation, flexibility in usage, and the ability to integrate easily into various application workflows. It provides a straightforward method for users to remain informed about their transcription tasks without the need for complex callback systems, making it an essential feature for many applications and services requiring transcription capabilities.
     * @param id 
     * @return void
     * @throws IllegalStateException If the request is not correctly configured
     * @throws IOException Rethrows the OkHttp execute method exception
     * @throws UnsupportedOperationException If the API returns an informational or redirection response
     * @throws ClientException If the API returns a client error response
     * @throws ServerException If the API returns a server error response
     */
    @Throws(IllegalStateException::class, IOException::class, UnsupportedOperationException::class, ClientException::class, ServerException::class)
    fun transcriptionGetById(id: java.util.UUID) : Unit {
        val localVarResponse = transcriptionGetByIdWithHttpInfo(id = id)

        return when (localVarResponse.responseType) {
            ResponseType.Success -> Unit
            ResponseType.Informational -> throw UnsupportedOperationException("Client does not support Informational responses.")
            ResponseType.Redirection -> throw UnsupportedOperationException("Client does not support Redirection responses.")
            ResponseType.ClientError -> {
                val localVarError = localVarResponse as ClientError<*>
                throw ClientException("Client error : ${localVarError.statusCode} ${localVarError.message.orEmpty()}", localVarError.statusCode, localVarResponse)
            }
            ResponseType.ServerError -> {
                val localVarError = localVarResponse as ServerError<*>
                throw ServerException("Server error : ${localVarError.statusCode} ${localVarError.message.orEmpty()} ${localVarError.body}", localVarError.statusCode, localVarResponse)
            }
        }
    }

    /**
     * Get transcription status and data
     * The /api/transcribe GET endpoint is a crucial component of the audio transcription service, designed to offer users a way to check the status of their transcription requests. This endpoint caters to the needs of users who prefer polling to monitor their requests over relying on webhook callbacks for real-time updates. Here&#39;s a detailed description of its functionality and how it integrates within the service:  ### Purpose and Functionality The primary purpose of the /api/transcribe GET endpoint is to provide users with the ability to manually inquire about the current status of their audio or video file transcription tasks. This endpoint supports a polling mechanism, where users can send a GET request at their convenience to receive the latest update on their transcription process.  ### How It Works Request: To utilize this endpoint, users initiate a GET request, including a unique identifier for the transcription task as a parameter. This identifier is provided by the service when the transcription request is first submitted. Response: In response to the GET request, the endpoint returns data about the transcription task&#39;s status. The response indicate that the transcription is still processing, has been completed, or has failed.  ### Response Details The response from the /api/transcribe GET endpoint includes several pieces of information that are crucial for users to understand the status and outcome of their transcription requests:  Status: Indicates the current state of the transcription task (e.g., Queued, Completed, Failed). Completion Details: If the transcription is completed, the response include details the resulting transcript.  ### Use Cases This endpoint is particularly useful for scenarios where users need or prefer to periodically check the status of their requests rather than implement real-time update mechanisms via webhooks. It provides flexibility in handling transcription tasks, allowing users to:  ### Advantages The /api/transcribe GET endpoint offers several advantages, including simplicity in implementation, flexibility in usage, and the ability to integrate easily into various application workflows. It provides a straightforward method for users to remain informed about their transcription tasks without the need for complex callback systems, making it an essential feature for many applications and services requiring transcription capabilities.
     * @param id 
     * @return ApiResponse<Unit?>
     * @throws IllegalStateException If the request is not correctly configured
     * @throws IOException Rethrows the OkHttp execute method exception
     */
    @Throws(IllegalStateException::class, IOException::class)
    fun transcriptionGetByIdWithHttpInfo(id: java.util.UUID) : ApiResponse<Unit?> {
        val localVariableConfig = transcriptionGetByIdRequestConfig(id = id)

        return request<Unit, Unit>(
            localVariableConfig
        )
    }

    /**
     * To obtain the request config of the operation transcriptionGetById
     *
     * @param id 
     * @return RequestConfig
     */
    fun transcriptionGetByIdRequestConfig(id: java.util.UUID) : RequestConfig<Unit> {
        val localVariableBody = null
        val localVariableQuery: MultiValueMap = mutableMapOf<kotlin.String, kotlin.collections.List<kotlin.String>>()
            .apply {
                put("id", listOf(id.toString()))
            }
        val localVariableHeaders: MutableMap<String, String> = mutableMapOf()
        localVariableHeaders["Accept"] = "application/problem+json"

        return RequestConfig(
            method = RequestMethod.GET,
            path = "/api/transcribe",
            query = localVariableQuery,
            headers = localVariableHeaders,
            requiresAuthentication = false,
            body = localVariableBody
        )
    }


    private fun encodeURIComponent(uriComponent: kotlin.String): kotlin.String =
        HttpUrl.Builder().scheme("http").host("localhost").addPathSegment(uriComponent).build().encodedPathSegments[0]
}
