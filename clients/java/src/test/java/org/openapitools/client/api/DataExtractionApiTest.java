/*
 * Studio - AI Empower Labs
 * # Studio API Documentation  ## Introduction Welcome to Studio by AI Empower Labs API documentation! We are thrilled to offer developers around the world access to our cutting-edge artificial intelligence technology and semantic search. Our API is designed to empower your applications with state-of-the-art AI capabilities, including but not limited to natural language processing, audio transcription, embedding, and predictive analytics.  Our mission is to make AI technology accessible and easy to integrate, enabling you to enhance your applications, improve user experiences, and innovate in your field. Whether you're building complex systems, developing mobile apps, or creating web services, our API provides you with the tools you need to incorporate AI functionalities seamlessly.  Support and Feedback We are committed to providing exceptional support to our developer community. If you have any questions, encounter any issues, or have feedback on how we can improve our API, please don't hesitate to contact our support team @ support@AIEmpowerLabs.com.  Terms of Use Please review our terms of use and privacy policy before integrating our API into your application. By using our API, you agree to comply with these terms.
 *
 * The version of the OpenAPI document: v1
 * Contact: support@aiempowerlabs.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package org.openapitools.client.api;

import org.openapitools.client.ApiException;
import org.openapitools.client.model.ApiExtractThematicSimilarityClusterPostRequest;
import org.openapitools.client.model.EmbeddingRequest;
import org.openapitools.client.model.EmbeddingResponse;
import java.io.File;
import org.openapitools.client.model.HttpValidationProblemDetails;
import org.openapitools.client.model.KMeansCluster;
import org.openapitools.client.model.KeywordExtractionRequestBody;
import org.openapitools.client.model.KeywordExtractionResponse;
import org.openapitools.client.model.NamedEntityRecognitionRequest;
import org.openapitools.client.model.NamedEntityRecognitionResponse;
import org.openapitools.client.model.ProblemDetails;
import org.openapitools.client.model.SemanticSimilarityRequest;
import org.openapitools.client.model.SemanticSimilarityResponse;
import org.openapitools.client.model.TokenCountRequest;
import org.openapitools.client.model.TokenCountResponse;
import org.openapitools.client.model.TokenizerRequest;
import org.openapitools.client.model.TokenizerResponse;
import org.openapitools.client.model.TranscriptionResponse;
import org.junit.jupiter.api.Disabled;
import org.junit.jupiter.api.Test;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

/**
 * API tests for DataExtractionApi
 */
@Disabled
public class DataExtractionApiTest {

    private final DataExtractionApi api = new DataExtractionApi();

    /**
     * Generate thematic similarity clusters using the K-Means algorithm
     *
     * @throws ApiException if the Api call fails
     */
    @Test
    public void apiExtractThematicSimilarityClusterPostTest() throws ApiException {
        ApiExtractThematicSimilarityClusterPostRequest apiExtractThematicSimilarityClusterPostRequest = null;
        KMeansCluster response = api.apiExtractThematicSimilarityClusterPost(apiExtractThematicSimilarityClusterPostRequest);
        // TODO: test validations
    }

    /**
     * Converts data to a numerical vector array
     *
     * The embedding endpoint is a sophisticated API designed for transforming textual data into high-dimensional vectors, facilitating a wide array of natural language processing (NLP) tasks. This transformation process encodes the semantic properties and contextual meanings of the input text into a vector space, enabling machines to understand and process language in a manner analogous to human comprehension.  ## Core Features:  * Semantic Encoding: Leverages advanced machine learning models, particularly those based on transformer architectures, to capture the deep semantic and syntactic nuances of the input text. This ensures that similar words and phrases are positioned closely in the vector space, reflecting their semantic proximity. * High-Dimensional Representation: Transforms texts into vectors in a high-dimensional space, typically ranging from hundreds to thousands of dimensions. This rich representation captures a comprehensive spectrum of linguistic features and relationships. * Scalability: Engineered to handle a wide range of text sizes, from short tweets to extensive documents, without compromising on the accuracy of the vector representations.
     *
     * @throws ApiException if the Api call fails
     */
    @Test
    public void embeddingTest() throws ApiException {
        EmbeddingRequest embeddingRequest = null;
        EmbeddingResponse response = api.embedding(embeddingRequest);
        // TODO: test validations
    }

    /**
     * Performs keyword extraction on source text
     *
     * This endpoint accepts a string of text and returns a list of key words or phrases that best describe the content of the text. This can be used for tagging, summarizing, indexing, or categorizing content.
     *
     * @throws ApiException if the Api call fails
     */
    @Test
    public void keywordExtractionTest() throws ApiException {
        KeywordExtractionRequestBody keywordExtractionRequestBody = null;
        KeywordExtractionResponse response = api.keywordExtraction(keywordExtractionRequestBody);
        // TODO: test validations
    }

    /**
     * Extracts named entities from provided text
     *
     * This endpoint accepts a string of text and returns a list of identified entities classified into categories such as email, location, organisation, etc.
     *
     * @throws ApiException if the Api call fails
     */
    @Test
    public void namedEntityRecognitionTest() throws ApiException {
        NamedEntityRecognitionRequest namedEntityRecognitionRequest = null;
        NamedEntityRecognitionResponse response = api.namedEntityRecognition(namedEntityRecognitionRequest);
        // TODO: test validations
    }

    /**
     * Generate semantic similarity queries from text
     *
     * Upon receiving a user-defined query and a set of texts, the endpoint processes this information through its semantic analysis engine. This engine leverages state-of-the-art machine learning models, such as transformer-based architectures, to encode the texts and the query into high-dimensional vectors. By operating in this semantic space, it can accurately measure the distances between the query vector and each of the text vectors, reflecting how closely the meanings align.  Use Cases:  * Content Discovery: Helps users find articles, posts, or documents that are most relevant to their query.  * Customer Support: Automatically matches customer queries to the most relevant FAQs or support documents.  * Research and Study: Assists researchers in quickly finding academic papers or resources that are closely related to their field of inquiry.  By utilizing the semantic similarity endpoint, organizations and individuals can greatly enhance the efficiency and effectiveness of their information retrieval processes, ensuring that users are connected with the content most pertinent to their needs.
     *
     * @throws ApiException if the Api call fails
     */
    @Test
    public void semanticSimilarityTest() throws ApiException {
        SemanticSimilarityRequest semanticSimilarityRequest = null;
        SemanticSimilarityResponse response = api.semanticSimilarity(semanticSimilarityRequest);
        // TODO: test validations
    }

    /**
     * Count tokens in a text
     *
     * The tokenCount endpoint designed for counting tokens in text data.
     *
     * @throws ApiException if the Api call fails
     */
    @Test
    public void tokenCountTest() throws ApiException {
        TokenCountRequest tokenCountRequest = null;
        TokenCountResponse response = api.tokenCount(tokenCountRequest);
        // TODO: test validations
    }

    /**
     * Converts data to a integer token array
     *
     * The tokenizer endpoint designed for transforming textual data into integer tokens.
     *
     * @throws ApiException if the Api call fails
     */
    @Test
    public void tokenizeTest() throws ApiException {
        TokenizerRequest tokenizerRequest = null;
        TokenizerResponse response = api.tokenize(tokenizerRequest);
        // TODO: test validations
    }

    /**
     * Synchronous transcribe audio
     *
     * The audio transcription endpoint is a specialized web service designed to convert spoken words from audio or video files into written text. This technology relies on advanced speech recognition algorithms to accurately transcribe the content of audio or video recordings. The endpoint typically accepts files in various formats, such as MP3, WAV for audio, and MP4, AVI for video, among others. Users can upload their files directly to the service, which then processes the audio track to extract the spoken words.  The transcription process involves several steps, including noise reduction to improve audio clarity, speaker diarization to identify and differentiate between different speakers, and the actual speech-to-text conversion. The result is a detailed transcript that captures the spoken content, often including timestamps and speaker labels for easy reference.  This service is particularly useful for journalists, researchers, podcasters, and professionals who need to convert meetings, interviews, lectures, or presentations into written form for analysis, sharing, or archival purposes. The endpoint may offer additional features like language detection, support for multiple languages, and customization options to improve transcription accuracy based on specific vocabulary or industry terms.  To use the audio transcription endpoint, developers typically integrate it into applications via API calls. These calls specify the file to be transcribed and any additional parameters required by the service, such as language preference.   Upon completion, the service returns the transcription in a JSON text format, which can then be displayed, stored, or further processed according to the user&#39;s needs.
     *
     * @throws ApiException if the Api call fails
     */
    @Test
    public void transcriptionSynchronousTest() throws ApiException {
        List<File> files = null;
        String model = null;
        String language = null;
        String prompt = null;
        Double temperature = null;
        Boolean splitOnWord = null;
        Boolean languageDetection = null;
        Boolean enableNoiseReduction = null;
        TranscriptionResponse response = api.transcriptionSynchronous(files, model, language, prompt, temperature, splitOnWord, languageDetection, enableNoiseReduction);
        // TODO: test validations
    }

}
