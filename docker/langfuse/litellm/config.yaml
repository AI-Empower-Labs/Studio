model_list:
  - model_name: llama3 ### RECEIVED MODEL NAME ###
    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: ollama/llama3 ### MODEL NAME sent to `litellm.completion()` ###
      api_base: http://llama3:11434

litellm_settings: # module level litellm settings - https://github.com/BerriAI/litellm/blob/main/litellm/__init__.py
  drop_params: True
  success_callback: ["langfuse"] # OPTIONAL - if you want to start sending LLM Logs to Langfuse. Make sure to set `LANGFUSE_PUBLIC_KEY` and `LANGFUSE_SECRET_KEY` in your env

router_settings: # router_settings are optional
  num_retries: 3
  timeout: 30 # 30 seconds
