{
    "AllowedHosts": "*",
    "ConnectionStrings": {
        "postgres": "Host=postgres;Port=5432;User Id=postgres;Database=postgres;SearchPath=public;Password=password;Pooling=true",
        "libraTranslate": "http://translation:5000",
        "redis": "redis"
    },
    "AiStudioOptions": {
        "FFMpegContainerNames": ["ael-ffmpeg-1"],
        "Llm": {
            "llama3.1": {
                "Default": "true",
                "Address": "http://llama3:11434/v1/chat/completions",
                "ContextSize": "8192",
                "DisplayName": "llama3 7B",
                "EmulateFunctionCalling": true,
                "Tokenizer": "llama",
                "ResponseReplacements": [
                    {
                        "Regex": "\"tool_calls\".*:.*null",
                        "Replacement": "\"tool_calls\":[]"
                    },
                    {
                        "Regex": "\"finish_reason\".*:.*\"eos\"",
                        "Replacement": "\"finish_reason\":\"stop\""
                    }
                ]
            }
        },
        "Embedding": {
            "intfloat/multilingual-e5-large-instruct": {
                "Default": true,
                "Address": "http://embedding:8080/embeddings",
                "MaxTokens": "512",
                "Dimensions": "1024",
                "DisplayName": "multilingual-e5-large",
                "Tokenizer": "multilingual-e5-large-instruct"
            }
        },
        "ReRanker": {
            "mixedbread-ai/mxbai-rerank-large-v1": {
                "Default": true,
                "Address": "http://embedding:8080/rerank",
                "DisplayName": "mxbai-rerank"
            }
        },
        "Transcription": {
            "AiEmpowerLabs": {
                "Default": "true",
                "Address": "http://transcription:8080"
            }
        }
    },
    "KernelMemory": {
        "DataIngestion": {
            "DefaultSteps": [
                "extract",
                "sanitize",
                "extract_audio",
                "partition",
                "gen_embeddings",
                "save_records"
            ],
            "TextPartitioning": {
                "MaxTokensPerParagraph": 512,
                "MaxTokensPerLine": 200,
                "OverlappingTokens": 80
            }
        },
        "Retrieval": {
            "SearchClient": {
                // Maximum number of tokens accepted by the LLM used to generate answers.
                // The number includes the tokens used for the answer, e.g. when using
                // GPT4-32k, set this number to 32768.
                // If the value is not set or less than one, SearchClient will use the
                // max amount of tokens supported by the model in use.
                "MaxAskPromptSize": -1,
                // Maximum number of relevant sources to consider when generating an answer.
                // The value is also used as the max number of results returned by SearchAsync
                // when passing a limit less or equal to zero.
                "MaxMatchesCount": 100,
                // How many tokens to reserve for the answer generated by the LLM.
                // E.g. if the LLM supports max 4000 tokens, and AnswerTokens is 300, then
                // the prompt sent to LLM will contain max 3700 tokens, composed by
                // prompt + question + grounding information retrieved from memory.
                "AnswerTokens": 300,
                // Text to return when the LLM cannot produce an answer.
                "EmptyAnswer": "INFO NOT FOUND!"
            }
        }
    },
    "Serilog": {
        "Using": [
            "Serilog.Sinks.Console",
            "Serilog.Enrichers.Environment",
            "Serilog.Enrichers.Thread",
            "Serilog.Exceptions"
        ],
        "MinimumLevel": {
            "Default": "Information",
            "Override": {
                "Npgsql": "Warning"
            }
        },
        "WriteTo": [
            {
                "Name": "Console",
                "Args": {
                    "restrictedToMinimumLevel": "Information",
                    "OutputTemplate": "[{Level:u4}] |{SourceContext,30}({EventId})| {Message:lj}{NewLine}{Exception}"
                }
            }
        ],
        "Properties": {
            "Application": "Studio"
        },
        "Enrich": [
            "FromLogContext",
            "WithEnvironmentUserName",
            "WithThreadId",
            "WithExceptionDetails"
        ]
    }
}
