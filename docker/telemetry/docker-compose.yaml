version: '3.8'  # Specifies the version of the Docker Compose file format

x-logging: &default-logging  # Defines a reusable logging configuration using YAML anchors
  options:
    max-size: "100m"  # Log rotation: max log size before rotation
    max-file: "5"  # Max number of log files to retain
  driver: json-file  # Specifies the logging driver, here using the default JSON file driver

x-defaults:
  environment: &environment  # Defines reusable environment variables for services
    OTEL_EXPORTER_OTLP_ENDPOINT: "http://collector:4317"  # Endpoint for OpenTelemetry collector

services:  # Defines the services part of the compose file
  host:  # Service definition for the main application host
    image: registry.aiempowerlabs.com/aistudio:latest  # Specifies the Docker image to use
    logging: *default-logging  # Uses the defined reusable logging configuration
    restart: unless-stopped  # Restart policy: restart if the container stops unexpectedly
    ports:
      - "8080:8080"  # Port mapping: Maps port 8080 of the container to port 8080 on the host
    environment:
      <<: *environment
      configPath: /opt/aistudio/  # Environment variable specifying the config path inside the container
    volumes:
      - ./appsettings.json:/opt/aistudio/appsettings.json  # Mounts a configuration file into the container
    networks:
      - ai_internal  # Connects the service to the internal network
      - ai_public  # Connects the service to the public network
    depends_on:  # Specifies dependencies on other services
      - postgres
      - translation
      - transcription
      - embedding
      - llama3

  postgres:  # PostgreSQL database service
    image: ankane/pgvector:latest  # Image to use for PostgreSQL with vector extension
    logging: *default-logging
    restart: unless-stopped
    environment:  # Database credentials
      <<: *environment
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password      
    healthcheck:  # Checks the health of the service
      test: ["CMD-SHELL", "sh -c 'pg_isready -U postgres -d postgres'"]
      interval: 10s  # Health check interval
      timeout: 3s  # Timeout for the health check
      retries: 3  # Number of retries before considering the service unhealthy
    networks:
      - ai_internal  # Connects the database service to the internal network only

  llama3:  # Service for LLM llama3
    image: registry.aiempowerlabs.com/llama3:latest
    logging: *default-logging
    restart: unless-stopped
    healthcheck:  # Health check using a curl command to a local endpoint
      test: ["CMD", "curl", "-f", "http://localhost:11434"]
      interval: 1m
      timeout: 20s
      retries: 5
    runtime: nvidia  # Specifies the runtime environment, necessary for GPU usage
    environment:
      <<: *environment
      NVIDIA_VISIBLE_DEVICES: all  # Makes all NVIDIA devices visible inside the container
    security_opt:
      - label=disable  # Disables security labeling within the container, necessary for some contexts
    networks:
      - ai_internal  # Connects to the internal network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia  # Reserves NVIDIA GPUs
              capabilities: [gpu]
              count: 1  # Specifies the number of GPUs

  translation:  # Translation service
    image: registry.aiempowerlabs.com/translation:latest  # Image to use for translation service
    logging: *default-logging  # Uses the reusable logging configuration
    restart: unless-stopped  # Restart policy: restart if the container stops unexpectedly
    environment:
      <<: *environment
    healthcheck:  # Health check command to ensure service availability
      test: ['CMD-SHELL', './venv/bin/python scripts/healthcheck.py']     
    networks:
      - ai_internal  # Connects the service to the internal network only

  transcription:  # Transcription service
    image: registry.aiempowerlabs.com/transcription:latest  # Image to use for transcription service
    logging: *default-logging
    restart: unless-stopped
    environment:
      <<: *environment
    healthcheck:  # Health check using a curl command to a local endpoint
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 1m  # Health check interval
      timeout: 10s  # Timeout for the health check
      retries: 3  # Number of retries before considering the service unhealthy
    networks:
      - ai_internal  # Connects to the internal network

  embedding:  # Embedding service
    image: registry.aiempowerlabs.com/multilingual-e5-large:latest  # Image to use for embedding service
    logging: *default-logging
    restart: unless-stopped
    environment:
      <<: *environment
    healthcheck:  # Health check using a curl command to a local endpoint
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 1m  # Health check interval
      timeout: 10s  # Timeout for the health check
      retries: 3  # Number of retries before considering the service unhealthy
    networks:
      - ai_internal  # Connects to the internal network

  collector:
    image: otel/opentelemetry-collector
    logging: *default-logging  # Uses the defined reusable logging configuration
    restart: unless-stopped
    command: ["--config=/etc/otel-collector-config.yaml"]  # Command to start the collector with a specified config
    volumes:
      - ./collector/otel-collector-config.yaml:/etc/otel-collector-config.yaml:cached
    ports:
      - 4317:4317 # App -> Collector
    networks:
      - ai_internal
    depends_on:
      - seq
      - jaeger
      - zipkin
      - prometheus
      - grafana
      - aspire

  seq:
    image: datalust/seq
    logging: *default-logging  # Uses the defined reusable logging configuration
    restart: unless-stopped
    environment:
      - ACCEPT_EULA=Y
    ports:
      - 8090:80
    networks:
      - ai_internal
      - ai_public

  jaeger:
    image: jaegertracing/all-in-one
    logging: *default-logging  # Uses the defined reusable logging configuration
    restart: unless-stopped
    ports:
      - 16686:16686
    networks:
      - ai_internal
      - ai_public

  zipkin:
    image: openzipkin/zipkin
    logging: *default-logging  # Uses the defined reusable logging configuration
    restart: unless-stopped
    ports:
      - 9411:9411
    networks:
      - ai_internal
      - ai_public

  prometheus:
    image: prom/prometheus
    logging: *default-logging  # Uses the defined reusable logging configuration
    restart: unless-stopped
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:cached
    networks:
      - ai_internal
      - ai_public

  grafana:
    image: grafana/grafana-enterprise
    logging: *default-logging  # Uses the defined reusable logging configuration
    restart: unless-stopped
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    volumes:
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    ports:
      - 3000:3000
    networks:
      - ai_internal
      - ai_public

  aspire:
    image: mcr.microsoft.com/dotnet/nightly/aspire-dashboard
    logging: *default-logging  # Uses the defined reusable logging configuration
    restart: unless-stopped
    ports:
      - 18888:18888
    networks:
      - ai_internal
      - ai_public

networks:
  ai_public: {}  # Definition of the public network
  ai_internal: {}  # Definition of the internal network
